{"cells":[{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"id":"VJvmIqaZkA6k"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import os\n","import yaml\n","import sys\n","import pandas as pd\n","import numpy as np\n","import json\n","dir_path = '/content/drive/Othercomputers/macbook-air/TPS-Mar2022/code'\n","os.chdir(dir_path)"],"metadata":{"id":"j0KCI5fEKJzB"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["! pip install japanize-matplotlib\n","! pip install shap\n","! pip install umap-learn\n","! pip install git+https://github.com/pfnet-research/xfeat.git"],"metadata":{"id":"KimabTiPj8T2"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"AjSWKReSiWro"},"outputs":[],"source":["CONFIG_FILE = '../configs/config.yaml'\n","\n","with open(CONFIG_FILE) as file:\n","    yml = yaml.safe_load(file)\n","\n","RAW_DIR_NAME = yml['SETTING']['RAW_DIR_NAME']\n","MODEL_DIR_NAME = yml['SETTING']['MODEL_DIR_NAME']\n","FEATURE_DIR_NAME = yml['SETTING']['FEATURE_DIR_NAME']\n","EDA_DIR_NAME = yml['SETTING']['EDA_DIR_NAME']\n","\n","# RAW_DIR_NAME = yml['SETTING']['RAW_DIR_NAME_IMP']\n","# FEATURE_DIR_NAME = yml['SETTING']['FEATURE_DIR_NAME_IMP']"]},{"cell_type":"code","source":["# ! python 1_generate_feature.py"],"metadata":{"id":"WgikczZDjgFy"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## 生データ確認"],"metadata":{"id":"a-kZG7K4q-P0"}},{"cell_type":"code","source":["train = pd.read_csv(RAW_DIR_NAME + 'train.csv')\n","test = pd.read_csv(RAW_DIR_NAME + 'test.csv')"],"metadata":{"id":"pQvx5LCrq9zx"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## datasets確認"],"metadata":{"id":"wwHQOTEqTtKs"}},{"cell_type":"code","source":["def load_datasets_train(feats):\n","    dfs = [pd.read_pickle(FEATURE_DIR_NAME + f'{f}_train.pkl') for f in feats]\n","    X_train = pd.concat(dfs, axis=1)\n","    return X_train\n","\n","def load_train_y(target):\n","    df = pd.read_pickle(FEATURE_DIR_NAME + f'{target}_train.pkl')\n","    return pd.Series(df[target])\n","\n","def load_datasets_both(feats):\n","    dfs = [pd.read_pickle(FEATURE_DIR_NAME + f'{f}_train.pkl') for f in feats]\n","    X_train = pd.concat(dfs, axis=1)\n","    dfs = [pd.read_pickle(FEATURE_DIR_NAME + f'{f}_test.pkl') for f in feats]\n","    X_test = pd.concat(dfs, axis=1)\n","    return X_train, X_test\n","\n","# 欠損値の確認\n","def missing_values_table(data):\n","    total = data.isnull().sum()\n","    percent = (data.isnull().sum()/data.isnull().count()*100)\n","    tt = pd.concat([total, percent], axis=1, keys=['Total', 'Percent'])\n","    types = []\n","    for col in data.columns:\n","        dtype = str(data[col].dtype)\n","        types.append(dtype)\n","    tt['Types'] = types\n","    return(np.transpose(tt))"],"metadata":{"id":"LSIQtZiFUDuw"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["run_name = 'lgb_0325_0159'\n","json_open = open(f'../models/{run_name}/{run_name}_param.json', 'r')\n","params = json.load(json_open)\n","pred = pd.read_pickle(f'../models/{run_name}/.{run_name}-train.pkl')\n","used_features = params['load_features']\n","target = params['dataset']['target']\n","\n","print('バリデーション:', params['cv']['method'])\n","print('特徴量:', used_features)\n","print('目的変数:', target)"],"metadata":{"id":"ONhQq_kaULzd"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["add_features = ['row_id', 'date_obj', 'direction']\n","features = used_features + add_features\n","\n","train_x, test_x = load_datasets_both(features)\n","train_y = load_train_y(target)\n","train_x_y = pd.concat([train_x, train_y], axis=1)"],"metadata":{"id":"8tndz12VrpTf"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["keep_index = ~train_x.isna().any(axis=1) & ~train_y.isna()\n","train_x, train_y = train_x.loc[keep_index, :].reset_index(), train_y[keep_index].reset_index()"],"metadata":{"id":"JHOyxIDO1PxY"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["true_data = pd.concat([train_x['row_id'], train_y[target]], axis=1)\n","pred_true = pred.merge(true_data).rename(columns={target: 'trueth'})\n","print('mae:', np.mean(abs(pred_true['pred'] - pred_true['trueth'])))"],"metadata":{"id":"rPp_0mxobAnN"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# 必要な特徴量を結合\n","pred_true = pred_true.merge(train_x[['row_id', 'x', 'y', 'direction', 'date_obj', 'accum_minutes']])\n","pred_true.head()"],"metadata":{"id":"DtZOguXwG1b6"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# predとtruethを1つの列にする\n","df_pred = pred_true.drop(['trueth'], axis=1).rename(columns = {'pred': target})\n","df_true = pred_true.drop(['pred'], axis=1).rename(columns = {'trueth': target})\n","df_pred['flag'] = 'pred'\n","df_true['flag'] = 'trueth'\n","df_fig = pd.concat([df_pred, df_true]).reset_index(drop=True)\n","df_fig.head()"],"metadata":{"id":"7t1cXHkOkgPr"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# ずれが大きい軸を調査\n","pred_true['ae'] = abs(pred_true['pred'] - pred_true['trueth'])\n","pred_true.groupby(['x', 'y', 'direction']).mean().join(pred_true.groupby(['x', 'y', 'direction']).std()['ae'].rename('std_ae')).sort_values('ae', ascending=False).head(30)"],"metadata":{"id":"ewDii7gdzBFd"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["sys.path.append('./src')\n","sys.path.append('./src/figures')\n","from src.figures.line_plots import PlotSeries5axis\n","\n","setting = {\n","    'run_name': '',  # run名\n","    'feature_dir_name': FEATURE_DIR_NAME,  # 特徴量の読み込み先ディレクトリ\n","}\n","\n","params = {\n","    'col': 'x',\n","    'row': 'y',\n","    'x': 'accum_minutes',\n","    'y': target,\n","    'z': 'flag',\n","    'is_xlim': True,\n","    'is_ylim': True\n","}\n","\n","# i = 2\n","# unique_directions = pred_true['direction'].unique()\n","# direction = unique_directions[i]\n","direction = 'NE'\n","\n","print(direction)\n","data = df_fig.query('direction == @direction')\n","\n","ps_5axis = PlotSeries5axis(params, features, setting=setting)\n","ps_5axis.data = data\n","ps_5axis.create_figure()"],"metadata":{"id":"XovCfmQ_vElz"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[""],"metadata":{"id":"b8ggHNp99kHC"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["x = 0\n","y = 0\n","row_ids = pred_true['row_id'].unique()\n","cols = ['date_obj', 'weekday', 'accum_minutes', 'shift1_congestion', 'shift2_congestion', 'shift3_congestion', 'date_direction_x_y_shift1_mean', 'rolling30_mean', 'congestion']\n","train_x_y.query('direction==@direction & x==@x & y==@y & row_id in @row_ids').sort_values('accum_minutes')[cols]"],"metadata":{"id":"G3icTe9ook5M"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["cols = ['date_obj', 'accum_minutes', 'x', 'y', 'direction', 'congestion']\n","\n","train_x_y['date_obj'] = pd.to_datetime(train_x_y['date_obj'])\n","train_x_y.query('direction==@direction & x==@x & y==@y & date_obj==\"1991-09-23\"').sort_values('accum_minutes')[cols].head(30)"],"metadata":{"id":"KTpjL5OqsGYH"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["cols = ['date_obj', 'x', 'y', 'direction', 'weekday']\n","pd.DataFrame(train_x_y.groupby(cols)['congestion'].mean())"],"metadata":{"id":"p-25jyGN5wEE"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## 画像保存\n"],"metadata":{"id":"ekakTlvynIxF"}},{"cell_type":"code","source":[""],"metadata":{"id":"f-ReCaOVT7rk"},"execution_count":null,"outputs":[]}],"metadata":{"colab":{"collapsed_sections":[],"name":"check_figure.ipynb","provenance":[],"private_outputs":true},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.2"}},"nbformat":4,"nbformat_minor":0}