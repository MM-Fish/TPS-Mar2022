{"cells":[{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"id":"VJvmIqaZkA6k"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import os\n","dir_path = '/content/drive/Othercomputers/macbook-air/TPS-Mar2022/code'\n","os.chdir(dir_path)"],"metadata":{"id":"j0KCI5fEKJzB"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["! pip install japanize-matplotlib\n","! pip install shap\n","! pip install umap-learn\n","! pip install git+https://github.com/pfnet-research/xfeat.git"],"metadata":{"id":"KimabTiPj8T2"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"AjSWKReSiWro"},"outputs":[],"source":["import glob\n","import sys,os\n","import json\n","import pprint\n","import time\n","import re\n","import datetime\n","import pickle\n","import string\n","import gc\n","import warnings\n","import yaml\n","import os\n","warnings.filterwarnings(\"ignore\")\n","sys.path.append(os.pardir)\n","sys.path.append('../..')\n","sys.path.append('../../..')\n","\n","import numpy as np\n","import pandas as pd\n","import pandas_profiling as pdp\n","import matplotlib.pyplot as plt\n","import japanize_matplotlib # 日本語対応\n","import seaborn as sns\n","# pandasのオプション\n","pd.set_option('display.max_columns', 300)\n","pd.set_option('display.max_rows', 300)\n","pd.set_option('display.max_colwidth', 5000)\n","pd.options.display.float_format = '{:.3f}'.format\n","%matplotlib inline\n","# sns.set_style('whitegrid')\n","plt.style.use('fivethirtyeight')\n","\n","from joblib import Parallel, delayed # よりお手軽にサクっと並列処理を実行出来るモジュール\n","from tqdm import tqdm, tqdm_notebook # プログレスバーを表示できる\n","from PIL import Image\n","tqdm.pandas()\n","\n","# 外部モジュールを自動的にリロードする\n","%load_ext autoreload\n","%autoreload 2\n","\n","CONFIG_FILE = '../configs/config.yaml'\n","\n","with open(CONFIG_FILE) as file:\n","    yml = yaml.safe_load(file)\n","MODEL_DIR_NAME = yml['SETTING']['MODEL_DIR_NAME']\n","FEATURE_DIR_NAME = yml['SETTING']['FEATURE_DIR_NAME']\n","RAW_DIR_NAME = yml['SETTING']['RAW_DIR_NAME']"]},{"cell_type":"code","source":["import os\n","dir_path = '/content/drive/Othercomputers/macbook-air/TPS-Mar2022/code'\n","os.chdir(dir_path)"],"metadata":{"id":"45jub0LJjiOy"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# ! python 1_generate_feature.py"],"metadata":{"id":"WgikczZDjgFy"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## 生データ確認"],"metadata":{"id":"a-kZG7K4q-P0"}},{"cell_type":"code","source":["train = pd.read_csv(RAW_DIR_NAME + 'train.csv')\n","train_imputation = pd.read_csv(RAW_DIR_NAME + 'train_imputation.csv')\n","test = pd.read_csv(RAW_DIR_NAME + 'test.csv')"],"metadata":{"id":"pQvx5LCrq9zx"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### memo(探索的データ分析)"],"metadata":{"id":"YDFerqsurfw8"}},{"cell_type":"code","source":["# 表形式特徴量算出\n","# train['time'] = pd.to_datetime(train['time'])\n","# display(train.describe(), train.describe(exclude='number'))\n","# #csvで保存するようにする？\n","\n","# 単変数\n","# x = 'direction'\n","# df = train.query('x==2 and y==3')\n","# target = 'congestion'\n","# func = sns.distplot\n","\n","# def plot_mono_variables(df, x, target, func):\n","#   unique_variables = train[x].unique()\n","#   n_xaxis = len(unique_variables)\n","#   fig, axes = plt.subplots(1, n_xaxis, figsize=(6*n_xaxis, 6))\n","#   print(unique_variables, x)\n","#   for i, v in enumerate(unique_variables):\n","#     df = df.loc[(df[x]==v), :]\n","#     func(df[target], ax=axes[i])\n","#     axes[i].set_title(f'{x}={v}')\n","\n","#   plt.subplots_adjust(hspace=0.4)\n","#   plt.show()\n","\n","# plot_mono_variables(df, x, target, func)\n","\n","# 変数間のグラフ\n","# カテゴリカル変数　× 数値変数\n","# fig, ax = plt.subplots(1, 3, figsize=(20, 10))\n","# sns.boxplot(data=train, x='direction', y='congestion', ax=ax[0])\n","# sns.boxplot(data=train, x='x', y='congestion', ax=ax[1])\n","# sns.boxplot(data=train, x='y', y='congestion', ax=ax[2])\n","\n","# train['direction'].unique()\n","# train['x'].unique()\n","# train['y'].unique()\n","\n","# 2変量\n","def plot_di_variables(df, x, y, target, func):\n","  unique_variables = np.meshgrid(df[x].unique(), df[y].unique())\n","  n_xaxis=len(df[x].unique())\n","  n_yaxis=len(df[y].unique())\n","\n","  fig, axes = plt.subplots(n_yaxis, n_xaxis, figsize=(10*n_yaxis, 10*n_xaxis))\n","\n","  for i in range(0, n_yaxis):\n","    for j in range(0, n_xaxis):\n","      x_value = unique_variables[0][i][j]\n","      y_value = unique_variables[1][i][j]\n","      print(x_value, y_value)\n","      data = df.loc[(df[x]==x_value) & (df[y]==y_value), :]\n","      func(data[target], ax=axes[i, j])\n","      axes[i,j].set_title(f'{x}={x_value}, {y}={y_value}')\n","\n","  plt.subplots_adjust(hspace=0.4)\n","  plt.show()\n","\n","# df = train.query('x==2 and y==3')\n","x = 'x'\n","y = 'y'\n","target = 'congestion'\n","func = sns.distplot\n","plot_di_variables(train, x, y, target, func)"],"metadata":{"id":"TY484-JQrfPE"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### memo(時系列データの欠損行の補完)\n"],"metadata":{"id":"sYtkwZa01dBw"}},{"cell_type":"code","source":["# 時系列データにおける欠損行の補完\n","def to_imputation(df, time_col, freq):\n","  df['merged_feat'] = df['x'].map(lambda x: str(x) + '_') + df['y'].map(lambda x: str(x) + '_') + df['direction']\n","\n","  df[time_col] = pd.to_datetime(df[time_col])\n","\n","  unique_time = pd.DataFrame(df[time_col].unique())\n","  max_time = unique_time.max()[0]\n","  min_time = unique_time.min()[0]\n","\n","  # 完全な時系列 * 特徴量のnp.arrayを作成\n","  absolute_series_arrary = np.meshgrid(np.array(pd.DataFrame(pd.date_range(start=min_time, end=max_time, freq=freq))), df['merged_feat'].unique())\n","\n","  absolute_series_index = pd.Series(absolute_series_arrary[0].flatten())\n","  absolute_series_values = pd.Series(absolute_series_arrary[1].flatten()).str.split('_', expand=True).rename(columns = {\n","    0: 'x',\n","    1: 'y',\n","    2: 'direction'\n","  })\n","\n","  absolute_series = pd.concat([absolute_series_index, absolute_series_values], axis=1).rename(columns={0: 'time'})\n","  absolute_series['x'] = absolute_series['x'].map(int)\n","  absolute_series['y'] = absolute_series['y'].map(int)\n","\n","  df_imputation = pd.merge(df, absolute_series, how='outer')\n","  print(df_imputation.shape)\n","  return df_imputation.drop(['merged_feat'], axis=1)"],"metadata":{"id":"q4Gx4jGF2a6R"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["time_col = 'time'\n","freq = '20min'\n","\n","df = to_imputation(train, time_col, freq)\n","display(df)\n","# df.to_csv('/content/drive/Othercomputers/macbook-air/TPS-Mar2022/data/raw/train_imputation.csv', index=False, mode='w')"],"metadata":{"id":"0Ki30IEP10zU"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## datasets確認"],"metadata":{"id":"fE7v1fX1nkt3"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"Pe-4WQI7iWry"},"outputs":[],"source":["def load_datasets_train(feats):\n","    dfs = [pd.read_pickle(FEATURE_DIR_NAME + f'{f}_train.pkl') for f in feats]\n","    X_train = pd.concat(dfs, axis=1)\n","    return X_train\n","\n","def load_train_y(target):\n","    df = pd.read_pickle(FEATURE_DIR_NAME + f'{target}_train.pkl')\n","    return pd.Series(df[target])\n","\n","def load_datasets_both(feats):\n","    dfs = [pd.read_pickle(FEATURE_DIR_NAME + f'{f}_train.pkl') for f in feats]\n","    X_train = pd.concat(dfs, axis=1)\n","    dfs = [pd.read_pickle(FEATURE_DIR_NAME + f'{f}_test.pkl') for f in feats]\n","    X_test = pd.concat(dfs, axis=1)\n","    return X_train, X_test\n","\n","# 欠損値の確認\n","def missing_values_table(data):\n","    total = data.isnull().sum()\n","    percent = (data.isnull().sum()/data.isnull().count()*100)\n","    tt = pd.concat([total, percent], axis=1, keys=['Total', 'Percent'])\n","    types = []\n","    for col in data.columns:\n","        dtype = str(data[col].dtype)\n","        types.append(dtype)\n","    tt['Types'] = types\n","    return(np.transpose(tt))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"5Zl0ZEOTiWr1"},"outputs":[],"source":["features = [\n","      # \"diff_3days\",\n","      # \"datetime_element\",\n","      # \"accum_minutes\",\n","      # \"x_y_direction_dummies\",\n","      # \"agg_shift_by_date\"\n","      'rawdata',\n","      'accum_minutes',\n","      'congestion'\n","    ]\n","\n","target = 'congestion'"]},{"cell_type":"code","source":["FEATURE_DIR_NAME = yml['SETTING']['FEATURE_DIR_NAME']\n","train_x, test_x = load_datasets_both(features)\n","train_y = load_train_y(target)"],"metadata":{"id":"8tndz12VrpTf"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["train_x"],"metadata":{"id":"405Szqn2rPvk"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## memo(移動平均)"],"metadata":{"id":"gSBIiwhn3DMQ"}},{"cell_type":"code","source":["cols = ['accum_minutes', 'direction', 'x', 'y']\n","agg_cols = ['min', 'max', 'mean', 'median']\n","target_col = 'congestion'\n","time_col = 'time'\n","\n","train[time_col] = pd.to_datetime(train[time_col])\n","train['accum_minutes'] = (train[time_col] - train[time_col].dt.floor('D')).dt.total_seconds() / 60\n","n_train = len(train)\n","\n","test[time_col] = pd.to_datetime(test[time_col])\n","test['accum_minutes'] = (test[time_col] - test[time_col].dt.floor('D')).dt.total_seconds() / 60\n","n_test = len(test)\n","\n","train_and_test = pd.concat([train, test]).reset_index(drop=True)\n","\n","# 1階差分shiftさせる（過去データを含まないようにするため）\n","train_and_test[target_col] = train_and_test.groupby(cols)[target_col].shift(1)\n","grp_df = train_and_test.groupby(cols)[target_col]\n","\n","outputs = []\n","for i in [50]:\n","    rolling_df = grp_df.rolling(i).agg(agg_cols)\n","    rolling_df = pd.DataFrame(rolling_df).add_prefix(f'rolling{i}_')\n","    rolling_df.index = rolling_df.index.map(lambda x: x[4])\n","    outputs.append(rolling_df.sort_index())"],"metadata":{"id":"YweFJDNA3CIm"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["df = pd.concat(outputs, axis=1).iloc[n_train:, :].reset_index(drop=True)\n","df = df.round()\n","submission_mean = df[['rolling50_mean']]\n","submission_mean.columns = ['congestion']\n","submission_mean = pd.concat([test, submission_mean], axis=1)\n","# save_dir = MODEL_DIR_NAME + '/mean-sub7/'\n","# submission_mean[['row_id', 'congestion']].to_csv(save_dir + 'submission.csv', index=False)\n","\n","submission_median = df[['rolling50_median']]\n","submission_median.columns = ['congestion']\n","submission_median = pd.concat([test, submission_median], axis=1)\n","# save_dir = MODEL_DIR_NAME + '/median-sub8/'\n","# submission_median[['row_id', 'congestion']].to_csv(save_dir + 'submission.csv', index=False)"],"metadata":{"id":"XZ5I7gNuM2NX"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["submission_median['congestion'] - submission_mean['congestion']"],"metadata":{"id":"prqZuJ9djDAj"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["outputs = [df]\n","grp_df = df.groupby(group)[feature_cols]\n","\n","for lag in [-3, -2, -1, 1, 2, 3]:\n","   # shift\n","   outputs.append(grp_df.shift(lag).add_prefix(f'shift{lag}_'))\n","   # diff\n","   outputs.append(grp_df.diff(lag).add_prefix(f'diff{lag}_'))"],"metadata":{"id":"cZXXWZV985pu"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## gcs"],"metadata":{"id":"ekakTlvynIxF"}},{"cell_type":"code","source":["# 特徴量保存\n","import os\n","dir_path = '/content/drive/Othercomputers/macbook-air/TPS-Mar2022/code'\n","os.chdir(dir_path)\n","sys.path.append('./')\n","from google.cloud import storage\n","from gcs_client import StorageClient\n","\n","os.environ['GOOGLE_APPLICATION_CREDENTIALS'] = '../gcs-key.json'\n","BUCKET_NAME = 'kaggleops-bucket-msm'\n","BLOB_NAME = 'data'\n","directry_path = f'../data/features/'\n","\n","client = storage.Client()\n","bucket = client.get_bucket(BUCKET_NAME)\n","StorageClient.upload_gcs_from_directory(bucket, directry_path, BLOB_NAME)"],"metadata":{"id":"-X1TWxVYnVeZ"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## モデルデータ確認"],"metadata":{"id":"hh8K_AQ8Vyti"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"K3m_pxs7iWr2"},"outputs":[],"source":["pd.read_pickle(MODEL_DIR_NAME + 'lgb_0306_1211/lgb_0306_1211-pred.pkl')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"wixxl1OuiWr3"},"outputs":[],"source":["# display(train.shape, test.shape)"]},{"cell_type":"code","source":["plt.bar([n for n in range(1, len(pca.explained_variance_ratio_)+1)], pca.explained_variance_ratio_)"],"metadata":{"id":"ptV3m1U8RpDa"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ptzKeTD7iWr4"},"outputs":[],"source":["# display(train.head(), train.tail(), train.shape)\n","# len(train[train['pca4'] > 0.01])\n","train.max()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"9V4rWygmiWr6"},"outputs":[],"source":["display(train.describe(), test.describe())"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"EhMeDqTJiWr7"},"outputs":[],"source":["# 各データの欠損値を確認\n","display(\n","    missing_values_table(train),\n","    missing_values_table(test)\n",")"]},{"cell_type":"markdown","source":["## create submission"],"metadata":{"id":"D5EXKPtBoS7p"}},{"cell_type":"code","source":["warnings.filterwarnings(\"ignore\")"],"metadata":{"id":"kuqhfa2MBl78"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["! python ../code/20_run.py"],"metadata":{"id":"Vt7bJPOFn6Af"},"execution_count":null,"outputs":[]}],"metadata":{"colab":{"collapsed_sections":["hh8K_AQ8Vyti","D5EXKPtBoS7p"],"name":"pickle_data_check.ipynb","provenance":[],"private_outputs":true},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.2"}},"nbformat":4,"nbformat_minor":0}